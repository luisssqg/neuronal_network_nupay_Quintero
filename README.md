📌 Descripción

Este proyecto grafica funciones de activación comunes en redes neuronales, incluyendo Sigmoid, ReLU y TanH, junto con sus derivadas.

📂 Estructura del Proyecto

📂 activation_functions/
├── 📂 src/
│   ├── sigmoid.py  # Implementación de Sigmoid y su derivada
│   ├── relu.py     # Implementación de ReLU y su derivada
│   ├── tanh.py     # Implementación de TanH y su derivada
├── main.py         # Script principal para graficar las funciones
├── README.md       # Documentación del proyecto

🛠️ Instalación

Asegúrate de tener Python y las siguientes dependencias instaladas:

pip install numpy matplotlib


🚀 Uso

Ejecuta el siguiente comando para visualizar las funciones de activación:

python main.py

Se generarán gráficos mostrando las funciones Sigmoid, ReLU y TanH junto con sus derivadas.


📈 Funcionalidad

Sigmoid y su derivada

ReLU y su derivada

TanH y su derivada

Visualización con Matplotlib


✉️ Contacto

Luis Daniel Quintero Gallegos
