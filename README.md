ğŸ“Œ DescripciÃ³n

Este proyecto grafica funciones de activaciÃ³n comunes en redes neuronales, incluyendo Sigmoid, ReLU y TanH, junto con sus derivadas.

ğŸ“‚ Estructura del Proyecto

ğŸ“‚ activation_functions/
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ sigmoid.py  # ImplementaciÃ³n de Sigmoid y su derivada
â”‚   â”œâ”€â”€ relu.py     # ImplementaciÃ³n de ReLU y su derivada
â”‚   â”œâ”€â”€ tanh.py     # ImplementaciÃ³n de TanH y su derivada
â”œâ”€â”€ main.py         # Script principal para graficar las funciones
â”œâ”€â”€ README.md       # DocumentaciÃ³n del proyecto

ğŸ› ï¸ InstalaciÃ³n

AsegÃºrate de tener Python y las siguientes dependencias instaladas:

pip install numpy matplotlib


ğŸš€ Uso

Ejecuta el siguiente comando para visualizar las funciones de activaciÃ³n:

python main.py

Se generarÃ¡n grÃ¡ficos mostrando las funciones Sigmoid, ReLU y TanH junto con sus derivadas.


ğŸ“ˆ Funcionalidad

Sigmoid y su derivada

ReLU y su derivada

TanH y su derivada

VisualizaciÃ³n con Matplotlib


âœ‰ï¸ Contacto

Luis Daniel Quintero Gallegos
